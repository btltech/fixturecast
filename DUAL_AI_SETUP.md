# ü§ñ Dual AI Model Setup - Complete Guide

## üéØ **What You Now Have**

You can now use **both Gemini and DeepSeek** in your FixtureCast app locally! Here's what's available:

### **New Components:**
1. **Unified Prediction Service** (`services/unifiedPredictionService.ts`)
2. **Model Selector** (`components/ModelSelector.tsx`) 
3. **Dual Model Prediction** (`components/DualModelPrediction.tsx`)
4. **Model Comparison Test** (`components/ModelComparisonTest.tsx`)

### **New Routes:**
- `/test-models` - Side-by-side comparison tool
- `/dual-prediction` - Interactive model selector with demo match

## üöÄ **How to Use Both Models**

### **Local DeepSeek Prediction Interface**
Visit: `http://localhost:5173/local-prediction`

This gives you:
- ‚úÖ Real match selection from multiple leagues
- ‚úÖ DeepSeek V3.1 Terminus predictions locally
- ‚úÖ Compare with your live site (Gemini predictions)
- ‚úÖ Detailed analysis and performance metrics
- ‚úÖ Perfect for A/B testing different AI models

### **Option 3: Integration in Your Code**

```typescript
import { unifiedPredictionService } from './services/unifiedPredictionService';

// Use Gemini (fast)
const geminiResult = await unifiedPredictionService.getPrediction(match, context, 'gemini');

// Use DeepSeek (detailed)  
const deepseekResult = await unifiedPredictionService.getPrediction(match, context, 'deepseek');

// Use both and compare
const bothResults = await unifiedPredictionService.getPrediction(match, context, 'both');

// Get the best prediction automatically
const bestPrediction = unifiedPredictionService.getBestPrediction(bothResults);
```

## üìä **Model Characteristics**

| Model | Speed | Quality | Best For |
|-------|-------|---------|----------|
| **Gemini 2.5 Flash** | ‚ö° Fast (15s) | High | Real-time predictions, user-facing |
| **DeepSeek V3.1** | üêå Slow (3min) | High | Detailed analysis, background processing |
| **Both Models** | üêå Slow (3min) | Comparison | Validation, accuracy testing |

## üéØ **Recommended Usage Patterns**

### **For Users (Real-time)**
```typescript
// Default to Gemini for speed
const prediction = await unifiedPredictionService.getPrediction(match, context, 'gemini');
```

### **For Analysis (Background)**
```typescript
// Use DeepSeek when you have time
const detailedPrediction = await unifiedPredictionService.getPrediction(match, context, 'deepseek');
```

### **For Validation**
```typescript
// Compare both models
const comparison = await unifiedPredictionService.getPrediction(match, context, 'both');
console.log('Models agree:', comparison.comparison?.similar);
```

## üîß **Integration Examples**

### **Add Model Selector to Existing Component**
```tsx
import ModelSelector from './ModelSelector';
import { unifiedPredictionService, PredictionModel } from '../services/unifiedPredictionService';

const [selectedModel, setSelectedModel] = useState<PredictionModel>('gemini');

// In your render:
<ModelSelector 
  selectedModel={selectedModel}
  onModelChange={setSelectedModel}
/>

// In your prediction function:
const result = await unifiedPredictionService.getPrediction(match, context, selectedModel);
```

### **Replace Existing Gemini Calls**
```typescript
// Old way:
import { getMatchPrediction } from './geminiService';
const prediction = await getMatchPrediction(match, context);

// New way (backward compatible):
import { getMatchPrediction } from './unifiedPredictionService'; 
const prediction = await getMatchPrediction(match, context, undefined, 'gemini');
```

## üí° **Production Strategies**

### **Strategy 1: User Choice**
Let users choose their preferred model:
- Fast mode (Gemini) for quick decisions
- Detailed mode (DeepSeek) for analysis

### **Strategy 2: Hybrid Approach**
- Use Gemini for real-time user requests
- Use DeepSeek for overnight batch processing
- Compare results for quality control

### **Strategy 3: Smart Switching**
- Use Gemini by default
- Fall back to DeepSeek if Gemini fails
- Use both for important matches

## üõ†Ô∏è **Current Configuration**

Your API keys are configured:
- ‚úÖ Gemini: `VITE_GEMINI_API_KEY`
- ‚úÖ DeepSeek: `VITE_DEEPSEEK_API_KEY`

Both models are ready to use in your local development environment!

## üéÆ **Try It Now**

1. **Local DeepSeek Predictions**: `http://localhost:5173/local-prediction`
2. **Compare with Live Site**: Generate same match prediction on both
3. **Integration**: Add `LocalPrediction` component anywhere

You now have the flexibility to use whichever AI model works best for each situation! üöÄ